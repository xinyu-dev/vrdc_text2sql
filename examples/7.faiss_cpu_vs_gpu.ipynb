{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5ba57d",
   "metadata": {},
   "source": [
    "# FAISS Retrieval Benchmarks CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd97d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27afc77e",
   "metadata": {},
   "source": [
    "# CPU Benchmark\n",
    "\n",
    "> To run this section, you need to create a new environment with `faiss-cpu` installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd4ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISSBenchmark:\n",
    "    \"\"\"Benchmark class for FAISS index creation and retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 4096):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.index = None\n",
    "        self.embeddings = None\n",
    "        self.benchmark_results = {\n",
    "            'index_creation_times': [],\n",
    "            'search_times': [],\n",
    "            'num_embeddings': [],\n",
    "            'num_queries': [],\n",
    "            'k_values': []\n",
    "        }\n",
    "    \n",
    "    def generate_dummy_embeddings(self, num_embeddings: int) -> np.ndarray:\n",
    "        \"\"\"Generate random embeddings for benchmarking\"\"\"\n",
    "        # Generate random embeddings normalized to unit length\n",
    "        embeddings = np.random.randn(num_embeddings, self.embedding_dim).astype('float32')\n",
    "        # Normalize embeddings\n",
    "        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        embeddings = embeddings / norms\n",
    "        return embeddings\n",
    "    \n",
    "    def create_index(self, embeddings: np.ndarray, index_type: str = 'flat') -> Tuple[faiss.Index, float]:\n",
    "        \"\"\"Create FAISS index and measure time\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "\n",
    "        index = faiss.IndexFlatL2(self.embedding_dim)\n",
    "        index.add(embeddings)\n",
    "        \n",
    "        creation_time = time.time() - start_time\n",
    "        print(f\"{index_type.upper()} index created with {index.ntotal} entries in {creation_time:.3f} seconds\")\n",
    "        \n",
    "        return index, creation_time\n",
    "    \n",
    "    def benchmark_search(self, index: faiss.Index, query_embeddings: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"Benchmark search performance\"\"\"\n",
    "        start_time = time.time()\n",
    "        distances, indices = index.search(query_embeddings, k)\n",
    "        search_time = time.time() - start_time\n",
    "        \n",
    "        avg_time_per_query = search_time / len(query_embeddings)\n",
    "        print(f\"Search completed: {len(query_embeddings)} queries, k={k}, total time: {search_time:.3f}s, avg: {avg_time_per_query*1000:.2f}ms/query\")\n",
    "        \n",
    "        return distances, indices, search_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c32c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_benchmark():\n",
    "    \"\"\"Run comprehensive benchmarks for different dataset sizes and index types\"\"\"\n",
    "    benchmark = FAISSBenchmark(embedding_dim=4096)\n",
    "    \n",
    "    # Test different dataset sizes\n",
    "    dataset_sizes = [1000, 5000, 10000, 50000]\n",
    "    index_types = ['flat']\n",
    "    k_values = [1, 5, 10, 50]\n",
    "    num_queries = 100\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for num_embeddings in dataset_sizes:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing with {num_embeddings} embeddings (dim={benchmark.embedding_dim})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Generate dummy data\n",
    "        print(f\"\\nGenerating {num_embeddings} dummy embeddings...\")\n",
    "        embeddings = benchmark.generate_dummy_embeddings(num_embeddings)\n",
    "        query_embeddings = benchmark.generate_dummy_embeddings(num_queries)\n",
    "        \n",
    "        for index_type in index_types:\n",
    "            print(f\"\\n--- Testing {index_type.upper()} index ---\")\n",
    "            \n",
    "            # Create index\n",
    "            index, creation_time = benchmark.create_index(embeddings, index_type)\n",
    "            \n",
    "            # Set search parameters for IVF\n",
    "            if index_type == 'ivf':\n",
    "                nprobe = min(64, index.nlist // 2)  # number of clusters to search\n",
    "                index.nprobe = nprobe\n",
    "                print(f\"IVF index: nprobe set to {nprobe}\")\n",
    "            \n",
    "            # Test different k values\n",
    "            for k in k_values:\n",
    "                if k <= num_embeddings:  # Only test k values that make sense\n",
    "                    distances, indices, search_time = benchmark.benchmark_search(index, query_embeddings, k)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'num_embeddings': num_embeddings,\n",
    "                        'index_type': index_type,\n",
    "                        'k': k,\n",
    "                        'num_queries': num_queries,\n",
    "                        'creation_time': creation_time,\n",
    "                        'total_search_time': search_time,\n",
    "                        'avg_search_time_ms': (search_time / num_queries) * 1000,\n",
    "                        'embedding_dim': benchmark.embedding_dim\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Simple FAISS Benchmark Example\n",
      "============================================================\n",
      "\n",
      "Generating 10000 embeddings with dimension 4096...\n",
      "Embeddings shape: (10000, 4096)\n",
      "Query embeddings shape: (100, 4096)\n",
      "Memory usage: ~156.2 MB\n",
      "\n",
      "----------------------------------------\n",
      "Testing FLAT Index\n",
      "----------------------------------------\n",
      "FLAT index created with 10000 entries in 0.028 seconds\n",
      "Search completed: 100 queries, k=10, total time: 0.106s, avg: 1.06ms/query\n",
      "\n",
      "Sample results for first query:\n",
      "Top 5 nearest neighbors: [2073  632 4796 3997  888]\n",
      "Distances: [1.8831728 1.8926971 1.8950738 1.896204  1.8965175]\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "Index Type      Creation Time   Avg Search Time     \n",
      "--------------------------------------------------\n",
      "FLAT            0.028s           1.06ms/query\n"
     ]
    }
   ],
   "source": [
    "# Simple benchmark example with smaller dataset\n",
    "def simple_benchmark_example():\n",
    "    \"\"\"Run a simple benchmark example with visualization\"\"\"\n",
    "    print(\"Running Simple FAISS Benchmark Example\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize benchmark with 4096-dimensional embeddings\n",
    "    benchmark = FAISSBenchmark(embedding_dim=4096)\n",
    "    \n",
    "    # Test parameters\n",
    "    num_embeddings = 10000\n",
    "    num_queries = 100\n",
    "    k = 10\n",
    "    \n",
    "    # Generate dummy embeddings\n",
    "    print(f\"\\nGenerating {num_embeddings} embeddings with dimension {benchmark.embedding_dim}...\")\n",
    "    embeddings = benchmark.generate_dummy_embeddings(num_embeddings)\n",
    "    query_embeddings = benchmark.generate_dummy_embeddings(num_queries)\n",
    "    \n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    print(f\"Query embeddings shape: {query_embeddings.shape}\")\n",
    "    print(f\"Memory usage: ~{embeddings.nbytes / (1024**2):.1f} MB\")\n",
    "    \n",
    "    # Test different index types\n",
    "    results = {}\n",
    "    index_types = ['flat']\n",
    "    \n",
    "    for index_type in index_types:\n",
    "        print(f\"\\n{'-'*40}\")\n",
    "        print(f\"Testing {index_type.upper()} Index\")\n",
    "        print(f\"{'-'*40}\")\n",
    "        \n",
    "        # Create index\n",
    "        index, creation_time = benchmark.create_index(embeddings, index_type)\n",
    "        \n",
    "        # Perform search\n",
    "        distances, indices, search_time = benchmark.benchmark_search(index, query_embeddings, k)\n",
    "        \n",
    "        # Store results\n",
    "        results[index_type] = {\n",
    "            'creation_time': creation_time,\n",
    "            'search_time': search_time,\n",
    "            'avg_search_time_ms': (search_time / num_queries) * 1000,\n",
    "            'distances': distances,\n",
    "            'indices': indices\n",
    "        }\n",
    "        \n",
    "        # Show sample results\n",
    "        print(f\"\\nSample results for first query:\")\n",
    "        print(f\"Top {min(5, k)} nearest neighbors: {indices[0][:5]}\")\n",
    "        print(f\"Distances: {distances[0][:5]}\")\n",
    "    \n",
    "    # Print comparison\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PERFORMANCE COMPARISON\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{'Index Type':<15} {'Creation Time':<15} {'Avg Search Time':<20}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    for index_type, result in results.items():\n",
    "        print(f\"{index_type.upper():<15} {result['creation_time']:.3f}s {' '*9} {result['avg_search_time_ms']:.2f}ms/query\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the simple benchmark\n",
    "simple_results = simple_benchmark_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a30f2b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# GPU benchmark\n",
    "\n",
    "> To run this section, you need to create a new evnrionment with faiss-gpu-cuvs installed\n",
    "\n",
    "```bash\n",
    "conda install -c pytorch -c nvidia -c rapidsai -c conda-forge libnvjitlink faiss-gpu-cuvs=1.11.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33c9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "from typing import Tuple, List\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0fababa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuVSFAISSBenchmark:\n",
    "    \"\"\"Benchmark class for cuVS GPU FAISS flat index creation and retrieval\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 4096, device: int = 0):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        # GPU resource handle\n",
    "        self.res = faiss.StandardGpuResources()\n",
    "        self.benchmark_results = {\n",
    "            'index_creation_times': [],\n",
    "            'search_times': [],\n",
    "            'num_embeddings': [],\n",
    "            'num_queries': [],\n",
    "            'k_values': []\n",
    "        }\n",
    "\n",
    "    def generate_dummy_embeddings(self, num_embeddings: int) -> np.ndarray:\n",
    "        \"\"\"Generate random unit‐normalized embeddings\"\"\"\n",
    "        emb = np.random.randn(num_embeddings, self.embedding_dim).astype('float32')\n",
    "        emb /= np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "        return emb\n",
    "\n",
    "    def create_gpu_flat_index(self, embeddings: np.ndarray) -> Tuple[faiss.Index, float]:\n",
    "        \"\"\"Build a cuVS flat L2 index on GPU and measure creation time.\"\"\"\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Configure cuVS\n",
    "        cfg = faiss.GpuIndexFlatConfig()\n",
    "        cfg.device = self.device\n",
    "        cfg.useFloat16 = False\n",
    "        cfg.use_cuvs = True\n",
    "\n",
    "        # Create GPU flat index\n",
    "        index_gpu = faiss.GpuIndexFlatL2(self.res, self.embedding_dim, cfg)\n",
    "        index_gpu.add(embeddings)\n",
    "\n",
    "        creation_time = time.time() - t0\n",
    "        print(f\"cuVS FLAT GPU index with {index_gpu.ntotal} entries created in {creation_time:.3f}s\")\n",
    "        return index_gpu, creation_time\n",
    "\n",
    "    def benchmark_search(self, index: faiss.Index, queries: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"Time a GPU‐based search.\"\"\"\n",
    "        t0 = time.time()\n",
    "        D, I = index.search(queries, k)\n",
    "        total = time.time() - t0\n",
    "        avg_ms = total / len(queries) * 1000\n",
    "        print(f\"GPU Search: {len(queries)} queries, k={k}, total={total:.3f}s, avg={avg_ms:.2f}ms/query\")\n",
    "        return D, I, total\n",
    "\n",
    "def run_gpu_benchmark():\n",
    "    bm = CuVSFAISSBenchmark(embedding_dim=4096, device=0)\n",
    "    dataset_sizes = [1000, 5000, 10000, 50000]\n",
    "    k_values       = [1, 5, 10, 50]\n",
    "    num_queries    = 100\n",
    "    \n",
    "    records = []\n",
    "    for N in dataset_sizes:\n",
    "        print(f\"\\n=== Benchmarking {N} embeddings ===\")\n",
    "        xb = bm.generate_dummy_embeddings(N)\n",
    "        xq = bm.generate_dummy_embeddings(num_queries)\n",
    "\n",
    "        # build index\n",
    "        index, t_create = bm.create_gpu_flat_index(xb)\n",
    "\n",
    "        for k in k_values:\n",
    "            if k <= N:\n",
    "                D, I, t_search = bm.benchmark_search(index, xq, k)\n",
    "                records.append({\n",
    "                    'num_embeddings': int(N),\n",
    "                    'creation_time_s': float(t_create),\n",
    "                    'k': int(k),\n",
    "                    'avg_search_time_ms': float(t_search / num_queries * 1000)\n",
    "                })\n",
    "\n",
    "    # Now it's safe to make a DataFrame of pure Python scalars:\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20da5a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmarking 1000 embeddings ===\n",
      "cuVS FLAT GPU index with 1000 entries created in 0.363s\n",
      "GPU Search: 100 queries, k=1, total=0.029s, avg=0.29ms/query\n",
      "GPU Search: 100 queries, k=5, total=0.001s, avg=0.01ms/query\n",
      "GPU Search: 100 queries, k=10, total=0.001s, avg=0.01ms/query\n",
      "GPU Search: 100 queries, k=50, total=0.003s, avg=0.03ms/query\n",
      "\n",
      "=== Benchmarking 5000 embeddings ===\n",
      "cuVS FLAT GPU index with 5000 entries created in 0.009s\n",
      "GPU Search: 100 queries, k=1, total=0.002s, avg=0.02ms/query\n",
      "GPU Search: 100 queries, k=5, total=0.001s, avg=0.01ms/query\n",
      "GPU Search: 100 queries, k=10, total=0.001s, avg=0.01ms/query\n",
      "GPU Search: 100 queries, k=50, total=0.001s, avg=0.01ms/query\n",
      "\n",
      "=== Benchmarking 10000 embeddings ===\n",
      "cuVS FLAT GPU index with 10000 entries created in 0.015s\n",
      "GPU Search: 100 queries, k=1, total=0.003s, avg=0.03ms/query\n",
      "GPU Search: 100 queries, k=5, total=0.002s, avg=0.02ms/query\n",
      "GPU Search: 100 queries, k=10, total=0.002s, avg=0.02ms/query\n",
      "GPU Search: 100 queries, k=50, total=0.002s, avg=0.02ms/query\n",
      "\n",
      "=== Benchmarking 50000 embeddings ===\n",
      "cuVS FLAT GPU index with 50000 entries created in 0.057s\n",
      "GPU Search: 100 queries, k=1, total=0.012s, avg=0.12ms/query\n",
      "GPU Search: 100 queries, k=5, total=0.011s, avg=0.11ms/query\n",
      "GPU Search: 100 queries, k=10, total=0.010s, avg=0.10ms/query\n",
      "GPU Search: 100 queries, k=50, total=0.011s, avg=0.11ms/query\n"
     ]
    }
   ],
   "source": [
    "records = run_gpu_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575075ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'num_embeddings': 1000,\n",
       "  'creation_time_s': 0.36345696449279785,\n",
       "  'k': 1,\n",
       "  'avg_search_time_ms': 0.2937960624694824},\n",
       " {'num_embeddings': 1000,\n",
       "  'creation_time_s': 0.36345696449279785,\n",
       "  'k': 5,\n",
       "  'avg_search_time_ms': 0.010058879852294922},\n",
       " {'num_embeddings': 1000,\n",
       "  'creation_time_s': 0.36345696449279785,\n",
       "  'k': 10,\n",
       "  'avg_search_time_ms': 0.00934600830078125},\n",
       " {'num_embeddings': 1000,\n",
       "  'creation_time_s': 0.36345696449279785,\n",
       "  'k': 50,\n",
       "  'avg_search_time_ms': 0.03309488296508789},\n",
       " {'num_embeddings': 5000,\n",
       "  'creation_time_s': 0.008816242218017578,\n",
       "  'k': 1,\n",
       "  'avg_search_time_ms': 0.018193721771240234},\n",
       " {'num_embeddings': 5000,\n",
       "  'creation_time_s': 0.008816242218017578,\n",
       "  'k': 5,\n",
       "  'avg_search_time_ms': 0.014033317565917969},\n",
       " {'num_embeddings': 5000,\n",
       "  'creation_time_s': 0.008816242218017578,\n",
       "  'k': 10,\n",
       "  'avg_search_time_ms': 0.014102458953857422},\n",
       " {'num_embeddings': 5000,\n",
       "  'creation_time_s': 0.008816242218017578,\n",
       "  'k': 50,\n",
       "  'avg_search_time_ms': 0.01432657241821289},\n",
       " {'num_embeddings': 10000,\n",
       "  'creation_time_s': 0.014589548110961914,\n",
       "  'k': 1,\n",
       "  'avg_search_time_ms': 0.0331568717956543},\n",
       " {'num_embeddings': 10000,\n",
       "  'creation_time_s': 0.014589548110961914,\n",
       "  'k': 5,\n",
       "  'avg_search_time_ms': 0.021963119506835938},\n",
       " {'num_embeddings': 10000,\n",
       "  'creation_time_s': 0.014589548110961914,\n",
       "  'k': 10,\n",
       "  'avg_search_time_ms': 0.022022724151611328},\n",
       " {'num_embeddings': 10000,\n",
       "  'creation_time_s': 0.014589548110961914,\n",
       "  'k': 50,\n",
       "  'avg_search_time_ms': 0.024237632751464844},\n",
       " {'num_embeddings': 50000,\n",
       "  'creation_time_s': 0.05685067176818848,\n",
       "  'k': 1,\n",
       "  'avg_search_time_ms': 0.11806249618530273},\n",
       " {'num_embeddings': 50000,\n",
       "  'creation_time_s': 0.05685067176818848,\n",
       "  'k': 5,\n",
       "  'avg_search_time_ms': 0.1050567626953125},\n",
       " {'num_embeddings': 50000,\n",
       "  'creation_time_s': 0.05685067176818848,\n",
       "  'k': 10,\n",
       "  'avg_search_time_ms': 0.10473966598510742},\n",
       " {'num_embeddings': 50000,\n",
       "  'creation_time_s': 0.05685067176818848,\n",
       "  'k': 50,\n",
       "  'avg_search_time_ms': 0.10748624801635742}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4f53704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average creation time: 0.065  s\n",
      "Average search time: 0.04  ms/query \n"
     ]
    }
   ],
   "source": [
    "print(\"Average creation time:\", np.round(np.average([r['creation_time_s'] for r in records]), 3), \" s\")\n",
    "print(\"Average search time:\", np.round(np.average([r['avg_search_time_ms'] for r in records]), 3), \" ms/query \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bae14",
   "metadata": {},
   "source": [
    "- CPU search time: 1.06ms/query\n",
    "- GPU-cuVS search time (1xA100-80G): 0.04  ms/query  -> **26.5x speed up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6431573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
