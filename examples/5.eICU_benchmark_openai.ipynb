{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ae477c",
   "metadata": {},
   "source": [
    "# eICU Benchmark with OpenAI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fafe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from loguru import logger\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'model_evaluation')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15012bcc",
   "metadata": {},
   "source": [
    "# Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de202ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input test set directory\n",
    "test_data_dir = \"../model_evaluation/dataset/test\"\n",
    "test_data_fp = os.path.join(test_data_dir, \"test_ehrsql_eicu_data_benchmark.json\")\n",
    "\n",
    "# try loading the test set\n",
    "with open(test_data_fp, \"r\") as f:\n",
    "    test_set = json.load(f)\n",
    "\n",
    "print(\"Size of test set:\", len(test_set))\n",
    "\n",
    "print(\"Example of a test set item:\")\n",
    "print(json.dumps(test_set[0], indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a705c",
   "metadata": {},
   "source": [
    "# Set up client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472b3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One fun fact about space is that there are more stars in the universe than there are grains of sand on all the Earth's beaches! Astronomers estimate that there are about 100 billion to 200 billion galaxies in the observable universe, each containing millions or even billions of stars. This means the total number of stars could be around 1 septillion (1 followed by 24 zeros), far exceeding the number of grains of sand on our planet!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "import json\n",
    "from loguru import logger\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "api_version=\"2025-04-01-preview\"\n",
    "azure_endpoint = \"https://prod.api.nvidia.com/llm/v1/azure\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "# Create a client instance\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"LLM_GATEWAY_API\"),\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "stream = False\n",
    "temperature = 0.7\n",
    "top_p = 0.7\n",
    "max_tokens = 256\n",
    " \n",
    "# Call the chat completion\n",
    "response = client.chat.completions.create(\n",
    "    model=model,  # This should match your deployment name in Azure\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a fun fact about space.\"}\n",
    "    ],\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    max_tokens=max_tokens,\n",
    "    stream=stream    \n",
    ")\n",
    " \n",
    "# Print the response\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90b9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
