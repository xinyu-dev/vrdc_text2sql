{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4390841a",
   "metadata": {},
   "source": [
    "# Text2SQL Combined with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa8cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'model_evaluation')))\n",
    "from utils import preprare_directory\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30d210",
   "metadata": {},
   "source": [
    "# Workflow Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716e9bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "144e03b3",
   "metadata": {},
   "source": [
    "**Features**:\n",
    "- By default, the whole DDL directly inserted into prompt. Though it can also be chunked\n",
    "- RAG is performed only on Q&A pairs from the training dataset\n",
    "- Default to retrieve top 3\n",
    "- No documentation RAG support\n",
    "- Async execution. Better than vanna because vanna doesn't support async. See [here](https://github.com/vanna-ai/vanna/discussions/394)\n",
    "- Using Faiss-CPU for now\n",
    "- Swap with different embeddings models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bb3f4",
   "metadata": {},
   "source": [
    "# Q&A Pair database\n",
    "\n",
    "The train and validation split of eICU is used as the vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97596138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Q&A pairs in the vector database:  10387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fp = \"/root/workspace/vrdc_text2sql/model_evaluation/dataset/train_eval/eicu/train_val.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "print(\"Number of Q&A pairs in the vector database: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354346b",
   "metadata": {},
   "source": [
    "# Steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2124d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789301ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predictions from:  /root/workspace/vrdc_text2sql/model_predictions/eICU/rag/mistral_finetuned_nv-embedqa_ddl5_qa6/test_rag_vllm_ehrsql_eicu_result_mis_embedd.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create output directory for evaluation results, relative to the path of model_evaluation directory\n",
    "# note that the evaluate results need a clean new folder, because it will overwrite any existing files in the folder\n",
    "pred_directory = f\"/root/workspace/vrdc_text2sql/model_predictions/eICU/rag/mistral_finetuned_nv-embedqa_ddl5_qa6\"  \n",
    "eval_directory = os.path.join(pred_directory, \"evaluation\")\n",
    "preprare_directory(eval_directory, exist_ok=False)\n",
    "\n",
    "# the predicted file from previous step\n",
    "pred_file = f\"{pred_directory}/test_rag_vllm_ehrsql_eicu_result_mis_embedd.jsonl\"\n",
    "\n",
    "print(\"Using predictions from: \", pred_file)\n",
    "\n",
    "# path to the eICU database\n",
    "db_path = \"/root/workspace/vrdc_text2sql/model_evaluation/databases/eicu.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c74a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation\n",
    "!python ../model_evaluation/ehrsql_eval.py \\\n",
    "    --pred_file {pred_file} \\\n",
    "    --db_path {db_path} \\\n",
    "    --num_workers -1 \\\n",
    "    --timeout 60 \\\n",
    "    --out_file {eval_directory} \\\n",
    "    --ndigits 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04c6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file:  /root/workspace/vrdc_text2sql/model_predictions/eICU/rag/mistral_finetuned_nv-embedqa_ddl5_qa6/evaluation/test_rag_vllm_ehrsql_eicu_result_mis_embedd_metrics.json\n",
      "{\n",
      "    \"precision_ans\": 100.0,\n",
      "    \"recall_ans\": 100.0,\n",
      "    \"f1_ans\": 100.0,\n",
      "    \"precision_exec\": 82.42,\n",
      "    \"recall_exec\": 82.42,\n",
      "    \"f1_exec\": 82.42,\n",
      "    \"acc\": 82.42\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# file path to the evaluation result file. \n",
    "fp = f\"{pred_directory}/evaluation/test_rag_vllm_ehrsql_eicu_result_mis_embedd_metrics.json\"\n",
    "print(\"Reading from file: \", fp)\n",
    "\n",
    "with open(fp, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70059a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
