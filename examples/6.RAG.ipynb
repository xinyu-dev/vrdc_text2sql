{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4390841a",
   "metadata": {},
   "source": [
    "# Text2SQL Combined with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa8cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'model_evaluation')))\n",
    "from utils import preprare_directory\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30d210",
   "metadata": {},
   "source": [
    "# Workflow Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716e9bf",
   "metadata": {},
   "source": [
    "![](/root/workspace/vrdc_text2sql/images/text2sql_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e03b3",
   "metadata": {},
   "source": [
    "**Features**:\n",
    "- By default, the whole DDL directly inserted into prompt. Though it can also be chunked\n",
    "- RAG is performed only on Q&A pairs from the training dataset\n",
    "- Default to retrieve top 3\n",
    "- No documentation RAG support\n",
    "- Async execution. Better than vanna because vanna doesn't support async. See [here](https://github.com/vanna-ai/vanna/discussions/394)\n",
    "- Using Faiss-CPU for now\n",
    "- Swap with different embeddings models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bb3f4",
   "metadata": {},
   "source": [
    "# Q&A Pair database\n",
    "\n",
    "The train and validation split of eICU is used as the vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97596138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Q&A pairs in the vector database:  10387\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fp = \"/root/workspace/vrdc_text2sql/model_evaluation/dataset/train_eval/eicu/train_val.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "print(\"Number of Q&A pairs in the vector database: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354346b",
   "metadata": {},
   "source": [
    "# Steps to run\n",
    "\n",
    "\n",
    "1. Confirm that your server still running:\n",
    "\t```\n",
    "\tcurl -v http://localhost:8000/health\n",
    "\t```\n",
    "2. First, create the output directory where you want to store the results, such as:\n",
    "\t```bash\n",
    "\tmkdir -p model_predictions/eICU/rag/mistral_finetuned_openai_embed \n",
    "\t```\n",
    "3. Run\n",
    "\t```bash\n",
    "\tpython model_inference/rag/mistral-text2sql-rag-vllm.py \\\n",
    "\t    --task_name ehrsql_eicu \\\n",
    "\t    --ip localhost \\\n",
    "\t    --port 8000 \\\n",
    "\t    --checkpoint_path /root/workspace/mistral-nemo-minitron-8b-healthcare-text2sql_v1.0 \\\n",
    "\t    --max_seq_length 4096 \\\n",
    "\t    --batch_size 4 \\\n",
    "\t    --save_dir model_predictions/eICU/rag/mistral_finetuned_openai_embed \\\n",
    "\t    --train_file model_evaluation/dataset/train_eval/eicu/train_val.csv \\\n",
    "\t    --embedding_model_name text-embedding-3-large \\\n",
    "\t    --embedding_cache_file model_evaluation/dataset/train_eval/eicu/train_database_openai-text-embedding-3-large.pkl \\\n",
    "\t    --top_k 3 \\\n",
    "\t    --dataset_path model_evaluation/dataset/test/test_ehrsql_eicu_data_benchmark_rag.json \\\n",
    "\t    --metadata_path model_evaluation/dataset/metadata/eicu_instruct_benchmark_rag.sql \\\n",
    "\t    --format sqlite\n",
    "\t```\n",
    "\n",
    "**Key Parameters:**\n",
    "\n",
    "- `--task_name`: Dataset name (e.g., ehrsql_eicu, mimicsql)\n",
    "- `--ip` and `--port`: vLLM server connection details\n",
    "- `--checkpoint_path`: Path to your fine-tuned model\n",
    "- `--train_file`: CSV file with training examples for RAG retrieval\n",
    "- `--embedding_model_name`: embedding model for vector search\n",
    "- `--embedding_cache_file`: Cache file for pre-computed embeddings. The pipeline will create embedding if this is not a valid, pre-existing file. \n",
    "- `--top_k`: Number of similar examples to retrieve (default: 3)\n",
    "- `--dataset_path`: Test dataset JSON file\n",
    "- `--metadata_path`: Database schema/metadata file\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- Model predictions in JSONL format\n",
    "- System performance metrics (memory, latency, throughput)\n",
    "- FAISS index cache for faster subsequent runs\n",
    "\n",
    "**Performance Optimization:**\n",
    "\n",
    "- Adjust `--batch_size` based on GPU memory\n",
    "- Use `--top_k` to control retrieval context size\n",
    "- Monitor memory usage and adjust `--max-num-seqs` accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2124d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789301ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predictions from:  /root/workspace/vrdc_text2sql/model_predictions/eICU/rag/claude_sonnet_4_no_thinking_ddl5_qa6/test_rag_vllm_ehrsql_eicu_result_mis_embedd.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create output directory for evaluation results, relative to the path of model_evaluation directory\n",
    "# note that the evaluate results need a clean new folder, because it will overwrite any existing files in the folder\n",
    "pred_directory = f\"/root/workspace/vrdc_text2sql/model_predictions/eICU/rag/claude_sonnet_4_no_thinking_ddl5_qa6\"  \n",
    "eval_directory = os.path.join(pred_directory, \"evaluation\")\n",
    "preprare_directory(eval_directory, exist_ok=False)\n",
    "\n",
    "# the predicted file from previous step\n",
    "pred_file = f\"{pred_directory}/test_rag_vllm_ehrsql_eicu_result_mis_embedd.jsonl\"\n",
    "\n",
    "print(\"Using predictions from: \", pred_file)\n",
    "\n",
    "# path to the eICU database\n",
    "db_path = \"/root/workspace/vrdc_text2sql/model_evaluation/databases/eicu.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c74a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation\n",
    "!python ../model_evaluation/ehrsql_eval.py \\\n",
    "    --pred_file {pred_file} \\\n",
    "    --db_path {db_path} \\\n",
    "    --num_workers -1 \\\n",
    "    --timeout 60 \\\n",
    "    --out_file {eval_directory} \\\n",
    "    --ndigits 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04c6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from file:  /root/workspace/vrdc_text2sql/model_predictions/eICU/rag/claude_sonnet_4_no_thinking_ddl5_qa6/evaluation/test_rag_vllm_ehrsql_eicu_result_mis_embedd_metrics.json\n",
      "{\n",
      "    \"precision_ans\": 100.0,\n",
      "    \"recall_ans\": 100.0,\n",
      "    \"f1_ans\": 100.0,\n",
      "    \"precision_exec\": 92.63,\n",
      "    \"recall_exec\": 92.63,\n",
      "    \"f1_exec\": 92.63,\n",
      "    \"acc\": 92.63\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# file path to the evaluation result file. \n",
    "fp = f\"{pred_directory}/evaluation/test_rag_vllm_ehrsql_eicu_result_mis_embedd_metrics.json\"\n",
    "print(\"Reading from file: \", fp)\n",
    "\n",
    "with open(fp, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70059a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
